Following common guidelines for empirical studies~\cite{yin2013case},  this section discusses the threats to validity of our study.

\subsection{Internal Validity} Internal validity concerns factors that could
have influenced our results. We rely on the NLP classification to determine \SATD. As mentioned earlier, this approach is not perfect, achieving an average precision of 0.72 and recall of 0.56. Although the precision and recall values are not very high, the NLP technique is considered the state-of-the-art in detecting \SATD. The NLP technique outperforms the comment-patterns technique, which all prior work was built on top of (i.e., \cite{Wehaibi2016SANER,Bavota2016MSR,Potdar2014ICSME}) by 230\%, on average. We train the Stanford NLP classifier on manually tagged \SATD comments provided in prior work~\cite{Maldonado2015TSE}. The manually classified comments have been verified and published in peer-reviewed venues.

To understand the type of activities that lead to the introduction and removal of \SATD, we conducted an online survey. We sent the survey to 188 developers who responsible for adding and removing self-admitted technical debt, and we received 14 (7.4\%) responses which may be considered small. However, a 7.4\% response rate is considered to be an acceptable response rate in questionnaire-based software engineering surveys~\cite{singer2008software}.

\subsection{Construct Validity} Threats to constructed validity concern the relationship between theory and observation.
To identify \SATD in a project, we use source code comments that describe part of the source code containing technical debt. One threat of using source code comments is the consistency of changes between the comments and the code, i.e., in some cases the comment may change and not the code and vice versa. However, previous work showed that between ~72 - 91\% of code and comment changes are consistent, i.e., code and comments co-change together~\cite{Potdar2014ICSME}. 


\rabe{To identify the removed and added \SATD, we consider the source code comments that do not exist in a source code file as removed of \SATD. However, in some cases source code can be moved from on file to another and not completely removed from source code of the project.} We also consider commits as a single unit of change. However, a single commit may contain other source code changes. Moreover, we rely on Open-hub's data to merge developer identities, hence, our study is only as accurate as Open-hub's classification.

\subsection{External Validity} Threats to external validity concern the generalization of our findings. Our study is conducted on five large open source projects and contains more than 5,700 comment removals. That said, our findings may not be generalized to other open source or commercial systems.